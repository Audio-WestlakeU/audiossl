manifest_path: "/20A021/dataset_from_dyl/manifest_ub/segment_random"
need_segmentation: True # TSV has segmentation with start_sec and end_sec
save_path: "/20A021/dataset_from_dyl/save_path/pretrainBase-0910"
nproc: 6
devices: 0,1,2,3,4,5
# 仍然使用原文给出的max_steps，保持训练曲线和原文复现一致，因为训练不以loss为准，要完成原文所制定的一个完整周期的训练
max_epochs: 200 #
#max_steps: 442500 # 邮件确认的超参数, 以data_size=1912024为准计算的，step/epoch=2212
warmup_epochs: 10
#warmup_steps: 22120
subset: 2000000 # 随机采样一部分, 不传入就使用全部训练样本
ds_size: 2000000
ema: 0.9996
learning_rate: 8.0e-5 # 1.0e-4
batch_size_per_gpu: 144 # 源代码用了6个GPU，总batch_size是864
symmetric: True
aug_tea: False #
aug_stu: True
arch: base
mask_ratio: 0.65
mask_type: "block"
sr: 16000
## 用于重新计算输入新的patch_w, 在audio_transformer.py, return FrameAST()
#n_fft: 2048 #
#win_length: 2048 #640 一般默认是hop_length的四倍, <=n_fft
#hop_length: 512  #160
anchor_len: 10
n_mels: 64 # 这个参数对应的是spec_h，与n_mels相同
#spec_w: 1292 # 原来的参数是1001，计算方式是 sr*anchor_len//hop_length + 1，这里的//是floor division. 对应于transform.py里num_patches的计算方式
patch_h: 64
patch_w: 4
mask_len: 5
pos_type: "cut"
num_workers: 20