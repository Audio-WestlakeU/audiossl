data_paths: [
  "/20A021/audioset/lmdb_ub/train_0.lmdb",
  "/20A021/audioset/lmdb_ub/train_1.lmdb",
  "/20A021/audioset/lmdb_ub/train_2.lmdb",
  "/20A021/audioset/lmdb_ub/train_3.lmdb",
  "/20A021/audioset/lmdb_ub/train_4.lmdb"
]
save_path: "/20A021/audioset/save_path/pretrain0723"
nproc: 8
devices: 0,1,2,3,4,5,6,7
# 仍然使用原文给出的max_steps，保持训练曲线和原文复现一致，因为训练不以loss为准，要完成原文所制定的一个完整周期的训练
#max_epochs: 200 #
max_steps: 398160 # 240 epochs, 刚开始训练了200epochs，331900 steps，loss曲线没有训练完全
#warmup_epochs: 10
warmup_steps: 16590
subset: 3000000 # 只要大于Audioset-2M的个数，就会使用全部样本，否则随机采样一部分
ds_size: 1912024
ema: 0.9996
learning_rate: 8.0e-5 # 1.0e-4
#batch_size_per_gpu: 128
batch_size_per_gpu: 144 # 源代码用了6个GPU，总batch_size是864
symmetric: True
aug_tea: False #
aug_stu: True
arch: base
mask_ratio: 0.65
mask_type: "block"
#sr: 22050  #16000
## 用于重新计算输入新的patch_w, 在audio_transformer.py, return FrameAST()
#n_fft: 2048 #
#win_length: 2048 #640 一般默认是hop_length的四倍, <=n_fft
#hop_length: 512  #160
anchor_len: 10
n_mels: 64 # 这个参数对应的是spec_h，与n_mels相同
#spec_w: 1292 # 原来的参数是1001，计算方式是 sr*anchor_len//hop_length + 1，这里的//是floor division. 对应于transform.py里num_patches的计算方式
patch_h: 64
patch_w: 4
mask_len: 5
pos_type: "cut"
num_workers: 10