manifest_path: "/20A021/dataset_from_dyl/manifest_ub/truncate"
need_segmentation: False # original tsv, just truncate.
save_path: "/20A021/dataset_from_dyl/save_path/pretrainSmall0903"
nproc: 4
devices: 0,1,2,3
#max_epochs: 200 #
max_steps: 58500 # 大概是300个epoch
#warmup_epochs: 10
warmup_steps: 1950
subset: 200000 # 随机采样一部分, 不传入就使用全部训练样本
ds_size: 200000
ema: 0.997
learning_rate: 4.0e-4
batch_size_per_gpu: 256
symmetric: True
aug_tea: False #
aug_stu: True
arch: small
mask_ratio: 0.65
mask_type: "block"
#sr: 22050  #16000
## 用于重新计算输入新的patch_w, 在audio_transformer.py, return FrameAST()
#n_fft: 2048 #
win_length: 640 #640 一般默认是hop_length的四倍, <=n_fft
#hop_length: 512  #160
anchor_len: 10
n_mels: 64 # 这个参数对应的是spec_h，与n_mels相同
#spec_w: 1292 # 原来的参数是1001，计算方式是 sr*anchor_len//hop_length + 1，这里的//是floor division. 对应于transform.py里num_patches的计算方式
patch_h: 64
patch_w: 4
mask_len: 5
pos_type: "cut"
num_workers: 20